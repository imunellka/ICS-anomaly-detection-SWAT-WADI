import numpy as np
import pandas as pd
import joblib
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score
from sklearn.preprocessing import StandardScaler
from typing import Tuple
import json


def train_isolation_forest_model(
    train_data: pd.DataFrame,
    test_data: pd.DataFrame,
    test_labels: np.ndarray,
    scaler: StandardScaler,
    model_path: str = "isolation_forest_model.pkl",
    metrics_path: str = "isolation_forest_metrics.json"
) -> Tuple[IsolationForest, dict]:
    """
    –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å Isolation Forest –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π.

    Args:
        train_data (pd.DataFrame): –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ (–±–µ–∑ –º–µ—Ç–æ–∫).
        test_data (pd.DataFrame): –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–±–µ–∑ –º–µ—Ç–æ–∫).
        test_labels (np.ndarray): –ú–µ—Ç–∫–∏ –¥–ª—è —Ç–µ—Å—Ç–∞ (1 ‚Äî –∞–Ω–æ–º–∞–ª–∏—è, 0 ‚Äî –Ω–æ—Ä–º–∞).
        scaler (StandardScaler): –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤—â–∏–∫, –æ–±—É—á–µ–Ω–Ω—ã–π –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ.
        model_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
        metrics_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫.

    Returns:
        Tuple: (–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å, —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏)
    """

    train_data = train_data.copy()
    test_data = test_data.copy()

    train_data["label"] = 0
    test_data["label"] = test_labels

    full_data = pd.concat([train_data, test_data], ignore_index=True)
    full_data = full_data.sample(frac=1, random_state=42).reset_index(drop=True)

    X = full_data.drop(columns=["label"])
    y = full_data["label"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )


    X_train_scaled = scaler.transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    contamination = y_train.mean()
    print(f"üìä –î–æ–ª—è –∞–Ω–æ–º–∞–ª–∏–π –≤ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ: {contamination:.4f}")

    model = IsolationForest(
        n_estimators=100,
        contamination=contamination,
        random_state=42
    )
    model.fit(X_train_scaled)

    y_pred = model.predict(X_test_scaled)
    y_pred = np.where(y_pred == -1, 1, 0)  # -1 ‚Üí 1 (–∞–Ω–æ–º–∞–ª–∏—è), 1 ‚Üí 0 (–Ω–æ—Ä–º–∞)

    metrics = {
        "roc_auc": roc_auc_score(y_test, y_pred),
        "f1_score": f1_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred)
    }

    print(f"üéØ ROC-AUC: {metrics['roc_auc']:.4f}")
    print(f"üéØ F1-score: {metrics['f1_score']:.4f}")
    print(f"üéØ Recall: {metrics['recall']:.4f}")
    print(f"üéØ Precision: {metrics['precision']:.4f}")

    joblib.dump(model, model_path)
    print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_path}")

    with open(metrics_path, "w") as f:
        json.dump(metrics, f, indent=4)
    print(f"üìÅ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {metrics_path}")

    return model, metrics
